import streamlit as st
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA

from scripts.config import PROMPT_TEMPLATE, SESSIONS_FILE, MODEL_CONFIGS
from scripts.vector_store_utils import load_vector_store
from scripts.llm_utils import load_llm
from scripts.graph_utils import search_neo4j_triples
from scripts.memory_utils import format_chat_history, concat_or_summarize
import json

# ---- ä¼šè¯è¯»å†™ ----
def load_sessions():
    if SESSIONS_FILE.exists():
        return json.loads(SESSIONS_FILE.read_text(encoding="utf-8"))
    return {}

def save_sessions(sessions):
    SESSIONS_FILE.write_text(json.dumps(sessions, ensure_ascii=False, indent=2), encoding="utf-8")

def render():
    st.subheader("ğŸ“˜ RAG é—®ç­”")

    # ä¼šè¯ç®¡ç†
    sessions = load_sessions()
    if not sessions:
        sessions["é»˜è®¤ä¼šè¯"] = []
        save_sessions(sessions)

    st.sidebar.subheader("ğŸ’¬ å¯¹è¯åˆ—è¡¨")
    selected = st.sidebar.selectbox("é€‰æ‹©å¯¹è¯", options=list(sessions.keys()))

    if st.sidebar.button("â• æ–°å»ºå¯¹è¯"):
        new_name = f"æ–°å¯¹è¯{len(sessions)+1}"
        sessions[new_name] = []
        save_sessions(sessions); st.rerun()

    if st.sidebar.button("ğŸ—‘ åˆ é™¤å½“å‰å¯¹è¯"):
        if selected in sessions:
            sessions.pop(selected)
            save_sessions(sessions); st.rerun()

    new_name = st.sidebar.text_input("âœï¸ é‡å‘½åå½“å‰å¯¹è¯", value=selected)
    if st.sidebar.button("ğŸ’¾ ä¿å­˜åç§°") and new_name.strip():
        if new_name != selected and new_name not in sessions:
            sessions[new_name] = sessions.pop(selected)
            save_sessions(sessions); st.rerun()
        elif new_name in sessions and new_name != selected:
            st.sidebar.warning("âš ï¸ å·²å­˜åœ¨åŒåå¯¹è¯ï¼Œè¯·æ¢ä¸€ä¸ªåå­—ã€‚")

    history = sessions.get(new_name if new_name in sessions else selected, [])

    # å‘é‡åº“
    try:
        db = load_vector_store()
    except Exception:
        st.warning("æœªæ£€æµ‹åˆ°å‘é‡åº“æˆ–åŠ è½½å¤±è´¥ï¼Œè¯·å…ˆåœ¨ã€ğŸ“‚ çŸ¥è¯†åº“ç®¡ç†ã€ä¸­æ„å»ºã€‚")
        db = None

    prompt = PromptTemplate(
        template=PROMPT_TEMPLATE,
        input_variables=["graph_info", "context", "question", "chat_history"]
    )
    model_choice = st.sidebar.selectbox("ğŸ¤– é€‰æ‹©æ¨¡å‹ï¼š", list(MODEL_CONFIGS.keys()))

    # å†å²å›æ”¾
    for chat in history:
        with st.chat_message("user"):
            st.markdown(chat["question"])
        with st.chat_message("assistant"):
            st.markdown(chat["answer"])
            if chat["sources"]:
                with st.expander("ğŸ“„ å‚è€ƒç‰‡æ®µ", expanded=False):
                    for i, s in enumerate(chat["sources"], 1):
                        st.markdown(f"**ç‰‡æ®µ{i}ï¼š{s['source']}**")
                        st.caption(s["content"][:300])

    # è¾“å…¥
    query = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...")
    if query and db is not None:
        with st.chat_message("user"):
            st.markdown(query)

        with st.spinner("ğŸ¤– æ€è€ƒä¸­..."):
            llm = load_llm(model_choice)
            retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": 8, "score_threshold": 0.3})
            graph_info = search_neo4j_triples(query) or "æš‚æ— ç›¸å…³å›¾è°±ä¿¡æ¯"

            chat_history_text = format_chat_history(history, max_rounds=8)
            chat_history_text = concat_or_summarize(chat_history_text, llm, max_tokens_hint=256)

            qa = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=retriever,
                return_source_documents=True,
                chain_type_kwargs={"prompt": prompt.partial(graph_info=graph_info, chat_history=chat_history_text)}
            )
            res = qa.invoke(query)
            answer = res["result"]

        with st.chat_message("assistant"):
            st.markdown(answer)
            if res["source_documents"]:
                with st.expander("ğŸ“„ å‚è€ƒç‰‡æ®µ", expanded=False):
                    for i, s in enumerate(res["source_documents"], 1):
                        st.markdown(f"**ç‰‡æ®µ{i}ï¼š{s.metadata.get('source','')}**")
                        st.caption(s.page_content[:300])

        # ä¿å­˜
        history.append({
            "question": query,
            "answer": answer,
            "sources": [
                {"source": doc.metadata.get("source", ""), "content": doc.page_content[:300] + "..."}
                for doc in res["source_documents"]
            ]
        })
        sessions[new_name if new_name in sessions else selected] = history
        save_sessions(sessions)
        st.rerun()

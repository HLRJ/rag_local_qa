# æ–‡ä»¶: scripts/remove_doc.py

import os
import json
import numpy as np
from pathlib import Path
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
import faiss

EMBEDDING_DIR = "../embeddings/faiss_store"
RECORD_FILE = "../embeddings/faiss_store/record.json"
EMBED_MODEL = "BAAI/bge-small-zh"

def load_indexed_files():
    if not os.path.exists(RECORD_FILE):
        return []
    with open(RECORD_FILE, "r", encoding="utf-8") as f:
        return json.load(f).get("indexed_files", [])

def save_indexed_files(file_list):
    with open(RECORD_FILE, "w", encoding="utf-8") as f:
        json.dump({"indexed_files": file_list}, f, ensure_ascii=False, indent=2)

def main():
    embed_model = HuggingFaceEmbeddings(model_name=EMBED_MODEL)

    vector_store_path = Path(EMBEDDING_DIR)
    if not vector_store_path.exists() or not Path(EMBEDDING_DIR, "index.faiss").exists():
        print("âŒ æœªæ‰¾åˆ°å‘é‡åº“ï¼Œè¯·å…ˆæ‰§è¡Œ build_vector_store.py")
        return

    file_to_remove = input("è¯·è¾“å…¥è¦ç§»é™¤çš„æ–‡ä»¶åï¼ˆä¾‹å¦‚ è¿ç»´æ‰‹å†Œ.pdfï¼‰: ").strip()
    indexed_files = load_indexed_files()
    if file_to_remove not in indexed_files:
        print(f"âš ï¸ æ–‡ä»¶ {file_to_remove} ä¸åœ¨å·²ç´¢å¼•è®°å½•ä¸­ï¼Œæ— éœ€ç§»é™¤ã€‚")
        return

    print("ğŸ”— åŠ è½½ç°æœ‰å‘é‡åº“...")
    db = FAISS.load_local(EMBEDDING_DIR, embed_model, allow_dangerous_deserialization=True)
    print("âœ… åŠ è½½å®Œæˆï¼Œå‡†å¤‡ç§»é™¤å‘é‡...")

    # è·å–ç°æœ‰ docstore ä¸­æ‰€æœ‰æ–‡æ¡£
    all_docs = list(db.docstore._dict.items())
    print(f"ğŸ“Š å½“å‰å‘é‡åº“æ–‡æ¡£æ€»æ•°ï¼š{len(all_docs)}")

    # æ‰¾å‡ºéœ€è¦ä¿ç•™çš„æ–‡æ¡£
    keep_doc_items = []
    keep_vectors = []
    for doc_id, doc in all_docs:
        source_file = doc.metadata.get("source", "")
        if source_file != file_to_remove:
            keep_doc_items.append((doc_id, doc))
            # ä»å‘é‡åº“ä¸­é‡æ„è¯¥æ–‡æ¡£çš„å‘é‡
            vec = db.index.reconstruct(int(doc_id))
            keep_vectors.append(vec)

    print(f"âœ… ä¿ç•™æ–‡æ¡£æ•°ï¼š{len(keep_doc_items)} ï¼ˆå·²ç§»é™¤ {len(all_docs) - len(keep_doc_items)} æ¡ï¼‰")

    # å¦‚æœä¸€ä¸ªéƒ½ä¸ä¿ç•™ï¼Œç›´æ¥æ¸…ç©º
    if not keep_doc_items:
        print("ğŸš¨ è­¦å‘Šï¼šå·²ç§»é™¤æ‰€æœ‰å‘é‡åº“æ¡ç›®ï¼Œå‘é‡åº“å°†è¢«æ¸…ç©ºã€‚")
        # æ–°å»ºä¸€ä¸ªç©ºå‘é‡åº“
        new_db = FAISS.from_documents([], embed_model)
        new_db.save_local(EMBEDDING_DIR)

        # æ›´æ–° record.json
        indexed_files.remove(file_to_remove)
        save_indexed_files(indexed_files)
        print(f"ğŸ‰ å·²æ¸…ç©ºå‘é‡åº“ï¼Œå¹¶æ›´æ–°ç´¢å¼•è®°å½•æ–‡ä»¶ã€‚")
        return

    # é‡å»ºç´¢å¼•
    dim = db.index.d
    new_index = faiss.IndexFlatL2(dim)
    new_index.add(np.array(keep_vectors).astype(np.float32))

    # é‡å»º docstore
    new_docstore = {}
    for doc_id, doc in keep_doc_items:
        new_docstore[doc_id] = doc

    # é‡å»º db
    new_db = FAISS(
        index=new_index,
        docstore=db.docstore.__class__(new_docstore),
        index_to_docstore_id={i: doc_id for i, (doc_id, _) in enumerate(keep_doc_items)},
        embedding_function=embed_model
    )

    new_db.save_local(EMBEDDING_DIR)

    # æ›´æ–° record.json
    indexed_files.remove(file_to_remove)
    save_indexed_files(indexed_files)
    print(f"ğŸ‰ å·²æˆåŠŸç§»é™¤ {file_to_remove} å¯¹åº”çš„å‘é‡ï¼Œå¹¶æ›´æ–°å‘é‡åº“ä¸è®°å½•æ–‡ä»¶ã€‚")

if __name__ == "__main__":
    main()

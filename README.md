# è¿ç»´æ™ºèƒ½é—®ç­”å¹³å°ï¼ˆRAG + ä¸­æ–‡æœ¬åœ°æ¨¡å‹ï¼‰

## ğŸ§  åŠŸèƒ½
- å¤šæ¨¡å‹ä¸­æ–‡LLMé—®ç­”ï¼ˆQwenã€Baichuanï¼‰
- ä¸­æ–‡å‘é‡åŒ–æ£€ç´¢ï¼ˆBAAI/bge-large-zhï¼‰
- Word/PDF/Excelä¸Šä¼ æ„å»ºçŸ¥è¯†åº“
- Streamlitäº¤äº’ç•Œé¢

## ğŸš€ å¿«é€Ÿå¼€å§‹
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æ„å»ºå‘é‡åº“
python scripts/build_vector_store.py

# å¯åŠ¨é—®ç­”ç•Œé¢
python scripts/run_web_ui.py
```

## ğŸ“‚ æ¨¡å‹ä¸‹è½½å»ºè®®ï¼ˆæ”¯æŒGGUFé‡åŒ–ç‰ˆå’Œsafetensorsæ ¼å¼ï¼‰
- Qwen: [Qwen1.5-1.8B](https://huggingface.co/Qwen/Qwen1.5-1.8B/tree/main) (ä¸‹è½½config.jsonã€model.safetensorsã€tokenizer.jsonã€tokenizer_config.jsonã€vocab.jsonã€merges.txtã€generation_config.jsonæ–‡ä»¶)
- THUDM: [glm-edge-1.5b-chat](https://huggingface.co/THUDM/glm-edge-1.5b-chat/tree/main)
- openbmb: [MiniCPM4-0.5B](https://huggingface.co/openbmb/MiniCPM4-0.5B/tree/main)
- TinyLlama: [TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/tree/main)
- [llama-2-7b.Q4_K_M](https://huggingface.co/TheBloke/Llama-2-7B-GGUF/tree/main)

å°†æ¨¡å‹ä¸‹è½½æ”¾å…¥ `models/` ç›®å½•ä¸‹ã€‚

## å®è·µ
- Baichuan2-7B-Chatã€Yi-1.5-6B-Chatåœ¨ç§»åŠ¨ç‰ˆ3060çˆ†æ˜¾å­˜
- æœ‰äº›ä¾èµ–å¿…é¡»åœ¨Linuxç¯å¢ƒä¸‹ï¼ŒWindowsç³»ç»Ÿæ— æ³•å®‰è£…
- MiniCPM-2B-sft-bf16ã€MiniCPM3-4B-GGUFç®€å•è°ƒè¯•åå‘ç°æ— æ³•é€‚é…
- llama-2-7b.Q4_K_Mæ¨¡å‹æ¨ç†å¦‚æœè®¾ç½®"gpu_layers"å‚æ•°çš„è¯ï¼Œå¯èƒ½ä¼šå¯¼è‡´å›ç­”æ•ˆæœé™ä½
- ç»¼åˆå¯¹æ¯”è¿˜æ˜¯qwenæ•ˆæœå¥½
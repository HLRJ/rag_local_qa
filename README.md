# è¿ç»´æ™ºèƒ½é—®ç­”å¹³å°ï¼ˆRAG + ä¸­æ–‡æœ¬åœ°æ¨¡å‹ï¼‰

## ğŸ§  åŠŸèƒ½
- å¤šæ¨¡å‹ä¸­æ–‡LLMé—®ç­”ï¼ˆQwenã€Baichuanï¼‰
- ä¸­æ–‡å‘é‡åŒ–æ£€ç´¢ï¼ˆBAAI/bge-large-zhï¼‰
- Word/PDF/Excelä¸Šä¼ æ„å»ºçŸ¥è¯†åº“
- Streamlitäº¤äº’ç•Œé¢

## ğŸ§° ç¯å¢ƒè¦æ±‚
å·²åœ¨win10/nvidia geforce rtx3060laptopæˆåŠŸè¿è¡Œï¼Œå¦‚éœ€è¿ç§»è‡³linuxç³»ç»Ÿï¼Œè¯·æ³¨æ„ä¿®æ”¹ç›®å½•è·¯å¾„çš„æ–œçº¿

## ğŸš€ å¿«é€Ÿå¼€å§‹
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æ„å»ºå‘é‡åº“
python scripts/build_vector_store.py

# å¯åŠ¨é—®ç­”ç•Œé¢
python scripts/run_web_ui.py
```

## ğŸ“¦ æ¨¡å‹ä¸‹è½½å»ºè®®ï¼ˆæ”¯æŒGGUFé‡åŒ–ç‰ˆå’Œsafetensorsæ ¼å¼ï¼‰
- Qwen: [Qwen1.5-1.8B](https://huggingface.co/Qwen/Qwen1.5-1.8B/tree/main)
- THUDM: [glm-edge-1.5b-chat](https://huggingface.co/THUDM/glm-edge-1.5b-chat/tree/main)
- openbmb: [MiniCPM4-0.5B](https://huggingface.co/openbmb/MiniCPM4-0.5B/tree/main)
- TinyLlama: [TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/tree/main)
- [llama-2-7b.Q4_K_M](https://huggingface.co/TheBloke/Llama-2-7B-GGUF/tree/main)

âœ… ä¸‹è½½åç»Ÿä¸€æ”¾ç½®åˆ° models/ ç›®å½•ä¸‹å¯¹åº”å­æ–‡ä»¶å¤¹ä¸­ã€‚

## ğŸ“ é¡¹ç›®ç›®å½•ç»“æ„

```text
â”‚  chat_history.json
â”‚  README.md
â”‚  requirements.txt
â”‚  test.py
â”‚
â”‚
â”œâ”€data
â”‚      Linuxå¸¸ç”¨å‘½ä»¤æ‰‹å†Œ.pdf    
â”‚
â”œâ”€embeddings
â”‚  â””â”€faiss_store
â”‚          index.faiss
â”‚          index.pkl
â”‚          record.json
â”‚
â”œâ”€models
â”‚  â”œâ”€llama
â”‚  â”‚      llama-2-7b.Q4_K_M.gguf
â”‚  â”‚
â”‚  â”œâ”€openbmb
â”‚  â”‚  â””â”€MiniCPM4-0.5B
â”‚  â”‚          added_tokens.json
â”‚  â”‚          config.json
â”‚  â”‚          configuration_minicpm.py
â”‚  â”‚          generation_config.json
â”‚  â”‚          model.safetensors
â”‚  â”‚          modeling_minicpm.py
â”‚  â”‚          special_tokens_map.json
â”‚  â”‚          tokenizer.json
â”‚  â”‚          tokenizer.model
â”‚  â”‚          tokenizer_config.json
â”‚  â”‚
â”‚  â”œâ”€Qwen
â”‚  â”‚  â””â”€Qwen1.5-1.8B
â”‚  â”‚          config.json
â”‚  â”‚          generation_config.json
â”‚  â”‚          merges.txt
â”‚  â”‚          model.safetensors
â”‚  â”‚          tokenizer.json
â”‚  â”‚          tokenizer_config.json
â”‚  â”‚          vocab.json
â”‚  â”‚
â”‚  â”œâ”€THUDM
â”‚  â”‚  â””â”€glm-edge-1.5b-chat
â”‚  â”‚          config.json
â”‚  â”‚          generation_config.json
â”‚  â”‚          model.safetensors
â”‚  â”‚          special_tokens_map.json
â”‚  â”‚          tokenizer.json
â”‚  â”‚          tokenizer_config.json
â”‚  â”‚
â”‚  â””â”€TinyLlama
â”‚      â””â”€TinyLlama-1.1B-Chat-v1.0
â”‚              config.json
â”‚              eval_results.json
â”‚              generation_config.json
â”‚              model.safetensors
â”‚              special_tokens_map.json
â”‚              tokenizer.json
â”‚              tokenizer.model
â”‚              tokenizer_config.json
â”‚
â”œâ”€scripts
â”‚      build_vector_store.py
â”‚      query_rag.py
â”‚      query_rag_mixed.py
â”‚      remove_doc.py
â”‚      run_web_ui.py
â”‚
â””â”€tools
        read_gguf_header.py
        test_ctransformers.py

```

## ğŸ” å®è·µ
- â— Baichuan2-7B-Chatã€Yi-1.5-6B-Chatåœ¨ç§»åŠ¨ç‰ˆ3060çˆ†æ˜¾å­˜
- ğŸ”§ æœ‰äº›ä¾èµ–å¿…é¡»åœ¨Linuxç¯å¢ƒä¸‹ï¼ŒWindowsç³»ç»Ÿæ— æ³•å®‰è£…
- âŒ MiniCPM-2B-sft-bf16ã€MiniCPM3-4B-GGUFç®€å•è°ƒè¯•åå‘ç°æ— æ³•é€‚é…
- âš™ï¸ llama-2-7b.Q4_K_Mæ¨¡å‹æ¨ç†å¦‚æœè®¾ç½®"gpu_layers"å‚æ•°çš„è¯ï¼Œå¯èƒ½ä¼šå¯¼è‡´å›ç­”æ•ˆæœé™ä½
- âœ… ç»¼åˆå¯¹æ¯”è¿˜æ˜¯qwenæ•ˆæœå¥½